{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f566615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gggg\n",
      "(128, 17, 2) (-1, 2)\n",
      "pose.shape torch.Size([17, 2])\n",
      "result.shape torch.Size([17, 2])\n",
      "torch.return_types.max(\n",
      "values=tensor([[23.6406]], device='cuda:0'),\n",
      "indices=tensor([[1]], device='cuda:0'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n",
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:125: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorrt as trt\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import os \n",
    "\n",
    "class Engine123:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_engine(self, runtime,engine_path):\n",
    "        trt.init_libnvinfer_plugins(None, \"\")             \n",
    "        with open(engine_path, 'rb') as f:\n",
    "            engine_data = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(engine_data)\n",
    "        return engine\n",
    " \n",
    "    \n",
    "    def make_context(self,trt_engine_path):\n",
    "        logger = trt.Logger(trt.Logger.WARNING)\n",
    "        runtime = trt.Runtime(logger)\n",
    "\n",
    "        self.engine = self.load_engine(runtime,trt_engine_path)\n",
    "        print('gggg')\n",
    "        self.context = self.engine.create_execution_context()\n",
    "\n",
    "        self.input_shape = self.engine.get_profile_shape(0,0)[2]\n",
    "        self.out_shape = self.engine.get_binding_shape(1)\n",
    "        print(self.input_shape,self.out_shape)\n",
    "    \n",
    "    def do_inference_v2(self, input_data):\n",
    "        img_batch = input_data.shape[0]  \n",
    "\n",
    "        self.out_shape[0] = img_batch\n",
    "        self.input_shape[0] = img_batch\n",
    "\n",
    "        output_data = torch.empty(size=tuple(self.out_shape), dtype=torch.float32, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "        self.context.set_binding_shape(0, tuple(self.input_shape))             \n",
    "\n",
    "        bindings = None     \n",
    "\n",
    "        bindings = [\n",
    "            int(input_data.contiguous().data_ptr())\n",
    "            ,int(output_data.data_ptr()) \n",
    "        ] \n",
    "\n",
    "        self.context.execute_async_v2(bindings,stream_handle=torch.cuda.current_stream().cuda_stream)   \n",
    "\n",
    "        return output_data\n",
    "      \n",
    "        \n",
    "    \n",
    "trt_engine_path = './dnn_128.trt'\n",
    "\n",
    "\n",
    "engine = Engine123()      \n",
    "engine.make_context(trt_engine_path)\n",
    "# #서있음\n",
    "# pose = [[ 96.080215 , 57.818184],\n",
    "#  [101.181816  ,57.818184],\n",
    "#  [ 97.78075   ,56.11765 ],\n",
    "#  [104.582886  ,68.02139 ],\n",
    "#  [119.8877    ,73.12299 ],\n",
    "#  [ 84.176476  ,90.12834 ],\n",
    "#  [128.39038  ,103.73262 ],\n",
    "#  [ 50.165775 , 59.51872 ],\n",
    "#  [159.       ,125.83958 ],\n",
    "#  [ 21.256685 , 22.106953],\n",
    "#  [141.99466  , 98.63102 ],\n",
    "#  [ 75.6738   ,178.55615 ],\n",
    "#  [106.283424 ,183.65776 ],\n",
    "#  [ 50.165775 ,229.57219 ],\n",
    "#  [118.187164 ,234.6738  ],\n",
    "#  [ 58.66845  ,299.29413 ],\n",
    "#  [141.99466  ,300.99466 ]]\n",
    "\n",
    "# 누워있음\n",
    "pose = [[ 297.92807,   -128.51799  ],\n",
    "  [ 356.34534    ,335.8993   ],\n",
    "  [ 213.22302    ,271.6403   ],\n",
    "  [ 204.46043    ,-67.179855 ],\n",
    "  [   8.76259   ,-151.8849   ],\n",
    "  [  58.417267  ,  14.604317 ],\n",
    "  [ 321.29498   , -87.6259   ],\n",
    "  [  -1.4604317 , 381.17267  ],\n",
    "  [  55.496407  , 110.99281  ],\n",
    "  [ 210.30217   , -26.287771 ],\n",
    "  [ 385.554     , -93.46763  ],\n",
    "  [ 116.83453   ,-148.96404  ],\n",
    "  [ 330.05756   , 137.28058  ],\n",
    "  [ 248.27339   , 370.94965  ],\n",
    "  [ 242.43166   , 125.59713  ],\n",
    "  [ 338.82016   , -32.129498 ],\n",
    "  [ 214.68346   ,-162.10793  ]]\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def _minMaxScaling(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    return scaler.transform(data)  \n",
    "\n",
    "\n",
    "pose = np.array(pose)\n",
    "\n",
    "s = time.time()\n",
    "pose = _minMaxScaling(pose)  \n",
    "# print('time',time.time()-s)\n",
    "# print('pose',pose)\n",
    "pose = torch.tensor(pose).to(dtype=torch.float32)   \n",
    "print('pose.shape',pose.shape)\n",
    "\n",
    "result = torch.empty([pose.shape[0], pose.shape[1]], dtype=torch.float32, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "print('result.shape',result.shape)\n",
    "# for i in range(5):\n",
    "#     if i == 1 :\n",
    "#         None\n",
    "    \n",
    "\n",
    "pose_list = [result for _ in range(1)]\n",
    "\n",
    "pose = torch.stack(pose_list,dim=0)\n",
    "pose = torch.tensor(pose).cuda() \n",
    "# print(pose.shape)  \n",
    "\n",
    "\n",
    "output_data = engine.do_inference_v2(pose) #결과 생성\n",
    "# print(output_data)\n",
    "# sm = nn.Softmax(doutput_data)\n",
    "# print(sm)\n",
    "pred = output_data.max(1, keepdim=True)\n",
    "print(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c120c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1.0000e+00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc961b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip은 튜플 형태를 반환하므로 (a,n)으로 묶어준다\n",
    "for i,(a,n) in enumerate(zip(alpha,num)):\n",
    "    print(i,a,n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
