{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be256ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt\n",
    "import cv2 as cv\n",
    "import torchvision\n",
    "import torch\n",
    "import time\n",
    "import common\n",
    "import vis\n",
    "import coco_classes\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\n",
    "def postprocess(prediction, num_classes, conf_thre=0.7, nms_thre=0.45, class_agnostic=False):\n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
    "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
    "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
    "\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    for i, image_pred in enumerate(prediction):\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "        class_conf, class_pred = torch.max(image_pred[:, 5: 5 + num_classes], 1, keepdim=True)\n",
    "\n",
    "        conf_mask = (image_pred[:, 4] * class_conf.squeeze() >= conf_thre).squeeze()\n",
    "        detections = torch.cat((image_pred[:, :5], class_conf, class_pred.float()), 1)\n",
    "        detections = detections[conf_mask]\n",
    "        if not detections.size(0):\n",
    "            continue\n",
    "\n",
    "        if class_agnostic:\n",
    "            nms_out_index = torchvision.ops.nms(\n",
    "                detections[:, :4],\n",
    "                detections[:, 4] * detections[:, 5],\n",
    "                nms_thre,\n",
    "            )\n",
    "        else:\n",
    "            nms_out_index = torchvision.ops.batched_nms(\n",
    "                detections[:, :4],\n",
    "                detections[:, 4] * detections[:, 5],\n",
    "                detections[:, 6],\n",
    "                nms_thre,\n",
    "            )\n",
    "\n",
    "        detections = detections[nms_out_index]\n",
    "        if output[i] is None:\n",
    "            output[i] = detections\n",
    "        else:\n",
    "            output[i] = torch.cat((output[i], detections))\n",
    "\n",
    "    return output\n",
    "\n",
    "def preproc(img, input_size, swap=(2, 0, 1)):\n",
    "    if len(img.shape) == 3:\n",
    "        padded_img = np.ones((input_size[0], input_size[1], 3), dtype=np.uint8) * 114\n",
    "    else:\n",
    "        padded_img = np.ones(input_size, dtype=np.uint8) * 114\n",
    "\n",
    "    r = min(input_size[0] / img.shape[0], input_size[1] / img.shape[1])\n",
    "    resized_img = cv.resize(\n",
    "        img,\n",
    "        (int(img.shape[1] * r), int(img.shape[0] * r)),\n",
    "        interpolation=cv.INTER_LINEAR,\n",
    "    ).astype(np.uint8)\n",
    "    padded_img[: int(img.shape[0] * r), : int(img.shape[1] * r)] = resized_img\n",
    "\n",
    "    padded_img = padded_img.transpose(swap)\n",
    "    padded_img = np.ascontiguousarray(padded_img, dtype=np.float32)\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "\n",
    "def img_process(img_path,batch_size):\n",
    "    ori_img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = preproc(ori_img,(640,640), swap=(2, 0, 1))\n",
    "    img_list = [img for _ in range(batch_size)]\n",
    "    img_stack = np.stack(img_list, axis=0)\n",
    "    return img_stack, ori_img\n",
    "\n",
    "\n",
    "def make_output(result,batch_size):\n",
    "    num_classes = 80\n",
    "    confthre =0.5\n",
    "    nmsthre  =0.3\n",
    "    result = np.reshape(result,(batch_size,1,-1))    \n",
    "    outputs = torch.Tensor(result)\n",
    "    outputs = outputs.view([batch_size, -1,num_classes+5]) \n",
    "    outputs = postprocess(\n",
    "        outputs, num_classes, confthre,\n",
    "        nmsthre, class_agnostic=True)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def visual(img, output, ratio, cls_conf=0.35):\n",
    "\n",
    "    if output is None:\n",
    "        return img\n",
    "    output = output.cpu()\n",
    "\n",
    "    bboxes = output[:, 0:4]\n",
    "\n",
    "    # preprocessing: resize\n",
    "    bboxes /= ratio\n",
    "\n",
    "    cls = output[:, 6]\n",
    "    scores = output[:, 4] * output[:, 5]\n",
    "\n",
    "    vis_res = vis.vis(img, bboxes, scores, cls, cls_conf, coco_classes.COCO_CLASSES)\n",
    "\n",
    "    return vis_res\n",
    "\n",
    "\n",
    "\n",
    "def test(trt_engine_path,img_path,batch_size,loop_cnt):\n",
    "\n",
    "    #Engine class 소환 \n",
    "    Engine = common.Engine()      \n",
    "    #inference에 필요한 context 만들어주기  \n",
    "    engine ,context, stream = Engine.make_context(trt_engine_path, batch_size)\n",
    "\n",
    "    #버퍼 할당해주기 \n",
    "    inputs = Engine.allocate_buffers(engine, batch_size, 'input')\n",
    "    output = Engine.allocate_buffers(engine, batch_size, 'output')\n",
    "    print(output['device_mem'])\n",
    "    img_stack, ori_img = img_process(img_path,batch_size)\n",
    "\n",
    "    for i in range(3):\n",
    "        input_data = torch.tensor(img_stack).cuda() #input 버퍼할당해 주지 않고 데이터를 바로 보낼때 \n",
    "        result = Engine.do_inference_v2(context, input_data, None, output, stream) #결과 생성\n",
    "  \n",
    "    total_time = 0\n",
    "    s3 = time.time()\n",
    "    for i in range(loop_cnt):\n",
    "        input_data = torch.tensor(img_stack).cuda() #input 버퍼할당해 주지 않고 데이터를 바로 보낼때 \n",
    "        result = Engine.do_inference_v2(context, input_data, None, output, stream) #결과 생성\n",
    "    e3 = time.time()\n",
    "    total_time += e3 - s3\n",
    "    \n",
    "#     print('평균 시간 : ',total_time/(loop_cnt))\n",
    "    average_total_time = total_time/(loop_cnt)\n",
    "\n",
    "    #postprocess\n",
    "    outputs = make_output(result,batch_size)\n",
    "    print(outputs)\n",
    "    out = outputs[0].shape[0]\n",
    "    \n",
    "    #save_img_path = '/DATA_17/ij/test.jpeg'  \n",
    "    # ratio = min(640 / ori_img.shape[0], 640 / ori_img.shape[1])\n",
    "    # result_image = visual(ori_img, outputs[0], ratio, cls_conf=0.35)\n",
    "    # cv.imwrite(save_img_path, result_image)\n",
    "\n",
    "    return round(average_total_time,5), batch_size, loop_cnt, out\n",
    "\n",
    "###############################실행##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ff55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "trt_dir = 'ij'\n",
    "targetDir = f'../engines/{trt_dir}/'\n",
    "\n",
    "#이미지 경로 설정     \n",
    "img_path = '/DATA_17/trt_test/test/test_image.jpeg'\n",
    "\n",
    "csv_save_path = f'./csv/{trt_dir}.csv'\n",
    "\n",
    "##targetDir에서 .xml파일 이름들 리스트로 가져오기\n",
    "trt_file_list = os.listdir(targetDir)\n",
    "\n",
    "trt_list = []\n",
    "for file in trt_file_list:\n",
    "    if '.trt' in file:\n",
    "        trt_list.append(file)\n",
    "\n",
    "trt_list = sorted(trt_list)\n",
    "\n",
    "\n",
    "with open(csv_save_path, 'w', encoding='UTF-8') as f:\n",
    "    w = csv.writer(f)\n",
    "    title = \"Model file_name trt_type make_batch test_batch average_time time_per_img output=5 loop_cnt\".split(\" \")\n",
    "    w.writerow(title)\n",
    "\n",
    "\n",
    "    for trt_file in trt_list:\n",
    "        engine_target_path = targetDir + trt_file\n",
    "        \n",
    "\n",
    "        f_name = trt_file.split('_')\n",
    "        max_batch_size = int(f_name[2][:-4])\n",
    "        trt_type = f_name[1]\n",
    "        model_name = f_name[0]\n",
    "\n",
    "        test_batch = [1]\n",
    "        \n",
    "        middle = int(max_batch_size/2)\n",
    "\n",
    "        if middle > 10 :\n",
    "            test_batch.append(int(middle/2))\n",
    "            test_batch.append(int(middle))\n",
    "            test_batch.append(int(middle/2 + middle))\n",
    "            test_batch.append(max_batch_size)\n",
    "        else : \n",
    "            test_batch.append(middle)\n",
    "            test_batch.append(max_batch_size)\n",
    "        best_time = []\n",
    "\n",
    "#5개만 돌릴때       \n",
    "#         for batch_size in test_batch :\n",
    "\n",
    "#1개씩 돌릴때 \n",
    "        for batch_size in range(1,max_batch_size+1) :\n",
    "            loop_cnt = int(1/batch_size) + 3 \n",
    "            average_total_time,batch_size,loop_cnt,out = test(engine_target_path,img_path,batch_size,loop_cnt)\n",
    "            print('trt_file :',trt_file,'batch_size: ',batch_size)\n",
    "            print('average_time: ',average_total_time)\n",
    "            \n",
    "            time_per_img = round(average_total_time/batch_size,5)\n",
    "            \n",
    "            best_time.append(time_per_img)\n",
    "            \n",
    "            data = f'{model_name} {trt_file} {trt_type} {max_batch_size} {batch_size} {average_total_time} {time_per_img} {out} {loop_cnt}'.split(\" \")\n",
    "            w.writerow(data)\n",
    "        \n",
    "        t_min = min(best_time)\n",
    "#         tmin_index = best_time.index(t_min) \n",
    "#         best_batch = test_batch[tmin_index]\n",
    "        tmin_index = best_time.index(t_min) +1\n",
    "        best_batch = tmin_index\n",
    "        s = '_'\n",
    "        t = 'best_batch'\n",
    "        p = 'time_per_img(batch)'\n",
    "        data = f'{s} {t} {best_batch} {p} {t_min} {s} {s} {s} {s}'.split(\" \")\n",
    "        w.writerow(data)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
