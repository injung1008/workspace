{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd82b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import cv2 as cv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cff9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    \"\"\"Convolution layer (conv + bn + relu).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            IN=False\n",
    "    ):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "            groups=groups\n",
    "        )\n",
    "        if IN:\n",
    "            self.bn = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "        else:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1x1(nn.Module):\n",
    "    \"\"\"1x1 convolution + bn + relu.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n",
    "        super(Conv1x1, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            1,\n",
    "            stride=stride,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "            groups=groups\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1x1Linear(nn.Module):\n",
    "    \"\"\"1x1 convolution + bn (w/o non-linearity).\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(Conv1x1Linear, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, 1, stride=stride, padding=0, bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv3x3(nn.Module):\n",
    "    \"\"\"3x3 convolution + bn + relu.\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, groups=1):\n",
    "        super(Conv3x3, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "            groups=groups\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LightConv3x3(nn.Module):\n",
    "    \"\"\"Lightweight 3x3 convolution.\n",
    "    1x1 (linear) + dw 3x3 (nonlinear).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(LightConv3x3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, 1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "            groups=out_channels\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "##########\n",
    "# Building blocks for omni-scale feature learning\n",
    "##########\n",
    "class ChannelGate(nn.Module):\n",
    "    \"\"\"A mini-network that generates channel-wise gates conditioned on input tensor.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            num_gates=None,\n",
    "            return_gates=False,\n",
    "            gate_activation='sigmoid',\n",
    "            reduction=16,\n",
    "            layer_norm=False\n",
    "    ):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        if num_gates is None:\n",
    "            num_gates = in_channels\n",
    "        self.return_gates = return_gates\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            in_channels // reduction,\n",
    "            kernel_size=1,\n",
    "            bias=True,\n",
    "            padding=0\n",
    "        )\n",
    "        self.norm1 = None\n",
    "        if layer_norm:\n",
    "            self.norm1 = nn.LayerNorm((in_channels // reduction, 1, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(\n",
    "            in_channels // reduction,\n",
    "            num_gates,\n",
    "            kernel_size=1,\n",
    "            bias=True,\n",
    "            padding=0\n",
    "        )\n",
    "        if gate_activation == 'sigmoid':\n",
    "            self.gate_activation = nn.Sigmoid()\n",
    "        elif gate_activation == 'relu':\n",
    "            self.gate_activation = nn.ReLU(inplace=True)\n",
    "        elif gate_activation == 'linear':\n",
    "            self.gate_activation = None\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                \"Unknown gate activation: {}\".format(gate_activation)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x\n",
    "        x = self.global_avgpool(x)\n",
    "        x = self.fc1(x)\n",
    "        if self.norm1 is not None:\n",
    "            x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        if self.gate_activation is not None:\n",
    "            x = self.gate_activation(x)\n",
    "        if self.return_gates:\n",
    "            return x\n",
    "        return input * x\n",
    "\n",
    "\n",
    "class OSBlock(nn.Module):\n",
    "    \"\"\"Omni-scale feature learning block.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            IN=False,\n",
    "            bottleneck_reduction=4,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super(OSBlock, self).__init__()\n",
    "        mid_channels = out_channels // bottleneck_reduction\n",
    "        self.conv1 = Conv1x1(in_channels, mid_channels)\n",
    "        self.conv2a = LightConv3x3(mid_channels, mid_channels)\n",
    "        self.conv2b = nn.Sequential(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.conv2c = nn.Sequential(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.conv2d = nn.Sequential(\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "            LightConv3x3(mid_channels, mid_channels),\n",
    "        )\n",
    "        self.gate = ChannelGate(mid_channels)\n",
    "        self.conv3 = Conv1x1Linear(mid_channels, out_channels)\n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = Conv1x1Linear(in_channels, out_channels)\n",
    "        self.IN = None\n",
    "        if IN:\n",
    "            self.IN = nn.InstanceNorm2d(out_channels, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x1 = self.conv1(x)\n",
    "        x2a = self.conv2a(x1)\n",
    "        x2b = self.conv2b(x1)\n",
    "        x2c = self.conv2c(x1)\n",
    "        x2d = self.conv2d(x1)\n",
    "        x2 = self.gate(x2a) + self.gate(x2b) + self.gate(x2c) + self.gate(x2d)\n",
    "        x3 = self.conv3(x2)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        out = x3 + identity\n",
    "        if self.IN is not None:\n",
    "            out = self.IN(out)\n",
    "        return F.relu(out)\n",
    "\n",
    "\n",
    "##########\n",
    "# Network architecture\n",
    "##########\n",
    "class OSNet(nn.Module):\n",
    "    \"\"\"Omni-Scale Network.\n",
    "\n",
    "    Reference:\n",
    "        - Zhou et al. Omni-Scale Feature Learning for Person Re-Identification. ICCV, 2019.\n",
    "        - Zhou et al. Learning Generalisable Omni-Scale Representations\n",
    "          for Person Re-Identification. TPAMI, 2021.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_classes,\n",
    "            blocks,\n",
    "            layers,\n",
    "            channels,\n",
    "            feature_dim=512,\n",
    "            loss='softmax',\n",
    "            IN=False,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super(OSNet, self).__init__()\n",
    "        num_blocks = len(blocks)\n",
    "        assert num_blocks == len(layers)\n",
    "        assert num_blocks == len(channels) - 1\n",
    "        self.loss = loss\n",
    "        self.feature_dim = feature_dim\n",
    "\n",
    "        # convolutional backbone\n",
    "        self.conv1 = ConvLayer(3, channels[0], 7, stride=2, padding=3, IN=IN)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.conv2 = self._make_layer(\n",
    "            blocks[0],\n",
    "            layers[0],\n",
    "            channels[0],\n",
    "            channels[1],\n",
    "            reduce_spatial_size=True,\n",
    "            IN=IN\n",
    "        )\n",
    "        self.conv3 = self._make_layer(\n",
    "            blocks[1],\n",
    "            layers[1],\n",
    "            channels[1],\n",
    "            channels[2],\n",
    "            reduce_spatial_size=True\n",
    "        )\n",
    "        self.conv4 = self._make_layer(\n",
    "            blocks[2],\n",
    "            layers[2],\n",
    "            channels[2],\n",
    "            channels[3],\n",
    "            reduce_spatial_size=False\n",
    "        )\n",
    "        self.conv5 = Conv1x1(channels[3], channels[3])\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        # fully connected layer\n",
    "        self.fc = self._construct_fc_layer(\n",
    "            self.feature_dim, channels[3], dropout_p=None\n",
    "        )\n",
    "        # identity classification layer\n",
    "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
    "\n",
    "        self._init_params()\n",
    "\n",
    "    def _make_layer(\n",
    "            self,\n",
    "            block,\n",
    "            layer,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            reduce_spatial_size,\n",
    "            IN=False\n",
    "    ):\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(in_channels, out_channels, IN=IN))\n",
    "        for i in range(1, layer):\n",
    "            layers.append(block(out_channels, out_channels, IN=IN))\n",
    "\n",
    "        if reduce_spatial_size:\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    Conv1x1(out_channels, out_channels),\n",
    "                    nn.AvgPool2d(2, stride=2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _construct_fc_layer(self, fc_dims, input_dim, dropout_p=None):\n",
    "        if fc_dims is None or fc_dims < 0:\n",
    "            self.feature_dim = input_dim\n",
    "            return None\n",
    "\n",
    "        if isinstance(fc_dims, int):\n",
    "            fc_dims = [fc_dims]\n",
    "\n",
    "        layers = []\n",
    "        for dim in fc_dims:\n",
    "            layers.append(nn.Linear(input_dim, dim))\n",
    "            layers.append(nn.BatchNorm1d(dim))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            if dropout_p is not None:\n",
    "                layers.append(nn.Dropout(p=dropout_p))\n",
    "            input_dim = dim\n",
    "\n",
    "        self.feature_dim = fc_dims[-1]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu'\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def featuremaps(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, return_featuremaps=False):\n",
    "        x = self.featuremaps(x)\n",
    "        if return_featuremaps:\n",
    "            return x\n",
    "        v = self.global_avgpool(x)\n",
    "        v = v.view(v.size(0), -1)\n",
    "        if self.fc is not None:\n",
    "            v = self.fc(v)\n",
    "        #         if not self.training:\n",
    "        #             return v\n",
    "        y = self.classifier(v)\n",
    "        if self.loss == 'softmax':\n",
    "            return y\n",
    "        elif self.loss == 'triplet':\n",
    "            return y, v\n",
    "        else:\n",
    "            raise KeyError(\"Unsupported loss: {}\".format(self.loss))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "def osnet_x1_0(num_classes=3, pretrained=False, loss='softmax', **kwargs):\n",
    "    # standard size (width x1.0)\n",
    "    model = OSNet(\n",
    "        num_classes,\n",
    "        blocks=[OSBlock, OSBlock, OSBlock],\n",
    "        layers=[2, 2, 2],\n",
    "        channels=[64, 256, 384, 512],\n",
    "        loss=loss,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0de5335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2weights = '/DATA/source/ij/pytorch_classfication/weights_osNet/class3/class3_last.pt'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = osnet_x1_0().to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(path2weights))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "439dd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 고정\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#분류기만 훈련시키기 \n",
    "model.classifier.requires_grad = True\n",
    "#분류기 피쳐 정의 \n",
    "model.classifier = nn.Linear(in_features=512, out_features=2, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31f2c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.conv.weight : False\n",
      "conv1.bn.weight : False\n",
      "conv1.bn.bias : False\n",
      "conv2.0.conv1.conv.weight : False\n",
      "conv2.0.conv1.bn.weight : False\n",
      "conv2.0.conv1.bn.bias : False\n",
      "conv2.0.conv2a.conv1.weight : False\n",
      "conv2.0.conv2a.conv2.weight : False\n",
      "conv2.0.conv2a.bn.weight : False\n",
      "conv2.0.conv2a.bn.bias : False\n",
      "conv2.0.conv2b.0.conv1.weight : False\n",
      "conv2.0.conv2b.0.conv2.weight : False\n",
      "conv2.0.conv2b.0.bn.weight : False\n",
      "conv2.0.conv2b.0.bn.bias : False\n",
      "conv2.0.conv2b.1.conv1.weight : False\n",
      "conv2.0.conv2b.1.conv2.weight : False\n",
      "conv2.0.conv2b.1.bn.weight : False\n",
      "conv2.0.conv2b.1.bn.bias : False\n",
      "conv2.0.conv2c.0.conv1.weight : False\n",
      "conv2.0.conv2c.0.conv2.weight : False\n",
      "conv2.0.conv2c.0.bn.weight : False\n",
      "conv2.0.conv2c.0.bn.bias : False\n",
      "conv2.0.conv2c.1.conv1.weight : False\n",
      "conv2.0.conv2c.1.conv2.weight : False\n",
      "conv2.0.conv2c.1.bn.weight : False\n",
      "conv2.0.conv2c.1.bn.bias : False\n",
      "conv2.0.conv2c.2.conv1.weight : False\n",
      "conv2.0.conv2c.2.conv2.weight : False\n",
      "conv2.0.conv2c.2.bn.weight : False\n",
      "conv2.0.conv2c.2.bn.bias : False\n",
      "conv2.0.conv2d.0.conv1.weight : False\n",
      "conv2.0.conv2d.0.conv2.weight : False\n",
      "conv2.0.conv2d.0.bn.weight : False\n",
      "conv2.0.conv2d.0.bn.bias : False\n",
      "conv2.0.conv2d.1.conv1.weight : False\n",
      "conv2.0.conv2d.1.conv2.weight : False\n",
      "conv2.0.conv2d.1.bn.weight : False\n",
      "conv2.0.conv2d.1.bn.bias : False\n",
      "conv2.0.conv2d.2.conv1.weight : False\n",
      "conv2.0.conv2d.2.conv2.weight : False\n",
      "conv2.0.conv2d.2.bn.weight : False\n",
      "conv2.0.conv2d.2.bn.bias : False\n",
      "conv2.0.conv2d.3.conv1.weight : False\n",
      "conv2.0.conv2d.3.conv2.weight : False\n",
      "conv2.0.conv2d.3.bn.weight : False\n",
      "conv2.0.conv2d.3.bn.bias : False\n",
      "conv2.0.gate.fc1.weight : False\n",
      "conv2.0.gate.fc1.bias : False\n",
      "conv2.0.gate.fc2.weight : False\n",
      "conv2.0.gate.fc2.bias : False\n",
      "conv2.0.conv3.conv.weight : False\n",
      "conv2.0.conv3.bn.weight : False\n",
      "conv2.0.conv3.bn.bias : False\n",
      "conv2.0.downsample.conv.weight : False\n",
      "conv2.0.downsample.bn.weight : False\n",
      "conv2.0.downsample.bn.bias : False\n",
      "conv2.1.conv1.conv.weight : False\n",
      "conv2.1.conv1.bn.weight : False\n",
      "conv2.1.conv1.bn.bias : False\n",
      "conv2.1.conv2a.conv1.weight : False\n",
      "conv2.1.conv2a.conv2.weight : False\n",
      "conv2.1.conv2a.bn.weight : False\n",
      "conv2.1.conv2a.bn.bias : False\n",
      "conv2.1.conv2b.0.conv1.weight : False\n",
      "conv2.1.conv2b.0.conv2.weight : False\n",
      "conv2.1.conv2b.0.bn.weight : False\n",
      "conv2.1.conv2b.0.bn.bias : False\n",
      "conv2.1.conv2b.1.conv1.weight : False\n",
      "conv2.1.conv2b.1.conv2.weight : False\n",
      "conv2.1.conv2b.1.bn.weight : False\n",
      "conv2.1.conv2b.1.bn.bias : False\n",
      "conv2.1.conv2c.0.conv1.weight : False\n",
      "conv2.1.conv2c.0.conv2.weight : False\n",
      "conv2.1.conv2c.0.bn.weight : False\n",
      "conv2.1.conv2c.0.bn.bias : False\n",
      "conv2.1.conv2c.1.conv1.weight : False\n",
      "conv2.1.conv2c.1.conv2.weight : False\n",
      "conv2.1.conv2c.1.bn.weight : False\n",
      "conv2.1.conv2c.1.bn.bias : False\n",
      "conv2.1.conv2c.2.conv1.weight : False\n",
      "conv2.1.conv2c.2.conv2.weight : False\n",
      "conv2.1.conv2c.2.bn.weight : False\n",
      "conv2.1.conv2c.2.bn.bias : False\n",
      "conv2.1.conv2d.0.conv1.weight : False\n",
      "conv2.1.conv2d.0.conv2.weight : False\n",
      "conv2.1.conv2d.0.bn.weight : False\n",
      "conv2.1.conv2d.0.bn.bias : False\n",
      "conv2.1.conv2d.1.conv1.weight : False\n",
      "conv2.1.conv2d.1.conv2.weight : False\n",
      "conv2.1.conv2d.1.bn.weight : False\n",
      "conv2.1.conv2d.1.bn.bias : False\n",
      "conv2.1.conv2d.2.conv1.weight : False\n",
      "conv2.1.conv2d.2.conv2.weight : False\n",
      "conv2.1.conv2d.2.bn.weight : False\n",
      "conv2.1.conv2d.2.bn.bias : False\n",
      "conv2.1.conv2d.3.conv1.weight : False\n",
      "conv2.1.conv2d.3.conv2.weight : False\n",
      "conv2.1.conv2d.3.bn.weight : False\n",
      "conv2.1.conv2d.3.bn.bias : False\n",
      "conv2.1.gate.fc1.weight : False\n",
      "conv2.1.gate.fc1.bias : False\n",
      "conv2.1.gate.fc2.weight : False\n",
      "conv2.1.gate.fc2.bias : False\n",
      "conv2.1.conv3.conv.weight : False\n",
      "conv2.1.conv3.bn.weight : False\n",
      "conv2.1.conv3.bn.bias : False\n",
      "conv2.2.0.conv.weight : False\n",
      "conv2.2.0.bn.weight : False\n",
      "conv2.2.0.bn.bias : False\n",
      "conv3.0.conv1.conv.weight : False\n",
      "conv3.0.conv1.bn.weight : False\n",
      "conv3.0.conv1.bn.bias : False\n",
      "conv3.0.conv2a.conv1.weight : False\n",
      "conv3.0.conv2a.conv2.weight : False\n",
      "conv3.0.conv2a.bn.weight : False\n",
      "conv3.0.conv2a.bn.bias : False\n",
      "conv3.0.conv2b.0.conv1.weight : False\n",
      "conv3.0.conv2b.0.conv2.weight : False\n",
      "conv3.0.conv2b.0.bn.weight : False\n",
      "conv3.0.conv2b.0.bn.bias : False\n",
      "conv3.0.conv2b.1.conv1.weight : False\n",
      "conv3.0.conv2b.1.conv2.weight : False\n",
      "conv3.0.conv2b.1.bn.weight : False\n",
      "conv3.0.conv2b.1.bn.bias : False\n",
      "conv3.0.conv2c.0.conv1.weight : False\n",
      "conv3.0.conv2c.0.conv2.weight : False\n",
      "conv3.0.conv2c.0.bn.weight : False\n",
      "conv3.0.conv2c.0.bn.bias : False\n",
      "conv3.0.conv2c.1.conv1.weight : False\n",
      "conv3.0.conv2c.1.conv2.weight : False\n",
      "conv3.0.conv2c.1.bn.weight : False\n",
      "conv3.0.conv2c.1.bn.bias : False\n",
      "conv3.0.conv2c.2.conv1.weight : False\n",
      "conv3.0.conv2c.2.conv2.weight : False\n",
      "conv3.0.conv2c.2.bn.weight : False\n",
      "conv3.0.conv2c.2.bn.bias : False\n",
      "conv3.0.conv2d.0.conv1.weight : False\n",
      "conv3.0.conv2d.0.conv2.weight : False\n",
      "conv3.0.conv2d.0.bn.weight : False\n",
      "conv3.0.conv2d.0.bn.bias : False\n",
      "conv3.0.conv2d.1.conv1.weight : False\n",
      "conv3.0.conv2d.1.conv2.weight : False\n",
      "conv3.0.conv2d.1.bn.weight : False\n",
      "conv3.0.conv2d.1.bn.bias : False\n",
      "conv3.0.conv2d.2.conv1.weight : False\n",
      "conv3.0.conv2d.2.conv2.weight : False\n",
      "conv3.0.conv2d.2.bn.weight : False\n",
      "conv3.0.conv2d.2.bn.bias : False\n",
      "conv3.0.conv2d.3.conv1.weight : False\n",
      "conv3.0.conv2d.3.conv2.weight : False\n",
      "conv3.0.conv2d.3.bn.weight : False\n",
      "conv3.0.conv2d.3.bn.bias : False\n",
      "conv3.0.gate.fc1.weight : False\n",
      "conv3.0.gate.fc1.bias : False\n",
      "conv3.0.gate.fc2.weight : False\n",
      "conv3.0.gate.fc2.bias : False\n",
      "conv3.0.conv3.conv.weight : False\n",
      "conv3.0.conv3.bn.weight : False\n",
      "conv3.0.conv3.bn.bias : False\n",
      "conv3.0.downsample.conv.weight : False\n",
      "conv3.0.downsample.bn.weight : False\n",
      "conv3.0.downsample.bn.bias : False\n",
      "conv3.1.conv1.conv.weight : False\n",
      "conv3.1.conv1.bn.weight : False\n",
      "conv3.1.conv1.bn.bias : False\n",
      "conv3.1.conv2a.conv1.weight : False\n",
      "conv3.1.conv2a.conv2.weight : False\n",
      "conv3.1.conv2a.bn.weight : False\n",
      "conv3.1.conv2a.bn.bias : False\n",
      "conv3.1.conv2b.0.conv1.weight : False\n",
      "conv3.1.conv2b.0.conv2.weight : False\n",
      "conv3.1.conv2b.0.bn.weight : False\n",
      "conv3.1.conv2b.0.bn.bias : False\n",
      "conv3.1.conv2b.1.conv1.weight : False\n",
      "conv3.1.conv2b.1.conv2.weight : False\n",
      "conv3.1.conv2b.1.bn.weight : False\n",
      "conv3.1.conv2b.1.bn.bias : False\n",
      "conv3.1.conv2c.0.conv1.weight : False\n",
      "conv3.1.conv2c.0.conv2.weight : False\n",
      "conv3.1.conv2c.0.bn.weight : False\n",
      "conv3.1.conv2c.0.bn.bias : False\n",
      "conv3.1.conv2c.1.conv1.weight : False\n",
      "conv3.1.conv2c.1.conv2.weight : False\n",
      "conv3.1.conv2c.1.bn.weight : False\n",
      "conv3.1.conv2c.1.bn.bias : False\n",
      "conv3.1.conv2c.2.conv1.weight : False\n",
      "conv3.1.conv2c.2.conv2.weight : False\n",
      "conv3.1.conv2c.2.bn.weight : False\n",
      "conv3.1.conv2c.2.bn.bias : False\n",
      "conv3.1.conv2d.0.conv1.weight : False\n",
      "conv3.1.conv2d.0.conv2.weight : False\n",
      "conv3.1.conv2d.0.bn.weight : False\n",
      "conv3.1.conv2d.0.bn.bias : False\n",
      "conv3.1.conv2d.1.conv1.weight : False\n",
      "conv3.1.conv2d.1.conv2.weight : False\n",
      "conv3.1.conv2d.1.bn.weight : False\n",
      "conv3.1.conv2d.1.bn.bias : False\n",
      "conv3.1.conv2d.2.conv1.weight : False\n",
      "conv3.1.conv2d.2.conv2.weight : False\n",
      "conv3.1.conv2d.2.bn.weight : False\n",
      "conv3.1.conv2d.2.bn.bias : False\n",
      "conv3.1.conv2d.3.conv1.weight : False\n",
      "conv3.1.conv2d.3.conv2.weight : False\n",
      "conv3.1.conv2d.3.bn.weight : False\n",
      "conv3.1.conv2d.3.bn.bias : False\n",
      "conv3.1.gate.fc1.weight : False\n",
      "conv3.1.gate.fc1.bias : False\n",
      "conv3.1.gate.fc2.weight : False\n",
      "conv3.1.gate.fc2.bias : False\n",
      "conv3.1.conv3.conv.weight : False\n",
      "conv3.1.conv3.bn.weight : False\n",
      "conv3.1.conv3.bn.bias : False\n",
      "conv3.2.0.conv.weight : False\n",
      "conv3.2.0.bn.weight : False\n",
      "conv3.2.0.bn.bias : False\n",
      "conv4.0.conv1.conv.weight : False\n",
      "conv4.0.conv1.bn.weight : False\n",
      "conv4.0.conv1.bn.bias : False\n",
      "conv4.0.conv2a.conv1.weight : False\n",
      "conv4.0.conv2a.conv2.weight : False\n",
      "conv4.0.conv2a.bn.weight : False\n",
      "conv4.0.conv2a.bn.bias : False\n",
      "conv4.0.conv2b.0.conv1.weight : False\n",
      "conv4.0.conv2b.0.conv2.weight : False\n",
      "conv4.0.conv2b.0.bn.weight : False\n",
      "conv4.0.conv2b.0.bn.bias : False\n",
      "conv4.0.conv2b.1.conv1.weight : False\n",
      "conv4.0.conv2b.1.conv2.weight : False\n",
      "conv4.0.conv2b.1.bn.weight : False\n",
      "conv4.0.conv2b.1.bn.bias : False\n",
      "conv4.0.conv2c.0.conv1.weight : False\n",
      "conv4.0.conv2c.0.conv2.weight : False\n",
      "conv4.0.conv2c.0.bn.weight : False\n",
      "conv4.0.conv2c.0.bn.bias : False\n",
      "conv4.0.conv2c.1.conv1.weight : False\n",
      "conv4.0.conv2c.1.conv2.weight : False\n",
      "conv4.0.conv2c.1.bn.weight : False\n",
      "conv4.0.conv2c.1.bn.bias : False\n",
      "conv4.0.conv2c.2.conv1.weight : False\n",
      "conv4.0.conv2c.2.conv2.weight : False\n",
      "conv4.0.conv2c.2.bn.weight : False\n",
      "conv4.0.conv2c.2.bn.bias : False\n",
      "conv4.0.conv2d.0.conv1.weight : False\n",
      "conv4.0.conv2d.0.conv2.weight : False\n",
      "conv4.0.conv2d.0.bn.weight : False\n",
      "conv4.0.conv2d.0.bn.bias : False\n",
      "conv4.0.conv2d.1.conv1.weight : False\n",
      "conv4.0.conv2d.1.conv2.weight : False\n",
      "conv4.0.conv2d.1.bn.weight : False\n",
      "conv4.0.conv2d.1.bn.bias : False\n",
      "conv4.0.conv2d.2.conv1.weight : False\n",
      "conv4.0.conv2d.2.conv2.weight : False\n",
      "conv4.0.conv2d.2.bn.weight : False\n",
      "conv4.0.conv2d.2.bn.bias : False\n",
      "conv4.0.conv2d.3.conv1.weight : False\n",
      "conv4.0.conv2d.3.conv2.weight : False\n",
      "conv4.0.conv2d.3.bn.weight : False\n",
      "conv4.0.conv2d.3.bn.bias : False\n",
      "conv4.0.gate.fc1.weight : False\n",
      "conv4.0.gate.fc1.bias : False\n",
      "conv4.0.gate.fc2.weight : False\n",
      "conv4.0.gate.fc2.bias : False\n",
      "conv4.0.conv3.conv.weight : False\n",
      "conv4.0.conv3.bn.weight : False\n",
      "conv4.0.conv3.bn.bias : False\n",
      "conv4.0.downsample.conv.weight : False\n",
      "conv4.0.downsample.bn.weight : False\n",
      "conv4.0.downsample.bn.bias : False\n",
      "conv4.1.conv1.conv.weight : False\n",
      "conv4.1.conv1.bn.weight : False\n",
      "conv4.1.conv1.bn.bias : False\n",
      "conv4.1.conv2a.conv1.weight : False\n",
      "conv4.1.conv2a.conv2.weight : False\n",
      "conv4.1.conv2a.bn.weight : False\n",
      "conv4.1.conv2a.bn.bias : False\n",
      "conv4.1.conv2b.0.conv1.weight : False\n",
      "conv4.1.conv2b.0.conv2.weight : False\n",
      "conv4.1.conv2b.0.bn.weight : False\n",
      "conv4.1.conv2b.0.bn.bias : False\n",
      "conv4.1.conv2b.1.conv1.weight : False\n",
      "conv4.1.conv2b.1.conv2.weight : False\n",
      "conv4.1.conv2b.1.bn.weight : False\n",
      "conv4.1.conv2b.1.bn.bias : False\n",
      "conv4.1.conv2c.0.conv1.weight : False\n",
      "conv4.1.conv2c.0.conv2.weight : False\n",
      "conv4.1.conv2c.0.bn.weight : False\n",
      "conv4.1.conv2c.0.bn.bias : False\n",
      "conv4.1.conv2c.1.conv1.weight : False\n",
      "conv4.1.conv2c.1.conv2.weight : False\n",
      "conv4.1.conv2c.1.bn.weight : False\n",
      "conv4.1.conv2c.1.bn.bias : False\n",
      "conv4.1.conv2c.2.conv1.weight : False\n",
      "conv4.1.conv2c.2.conv2.weight : False\n",
      "conv4.1.conv2c.2.bn.weight : False\n",
      "conv4.1.conv2c.2.bn.bias : False\n",
      "conv4.1.conv2d.0.conv1.weight : False\n",
      "conv4.1.conv2d.0.conv2.weight : False\n",
      "conv4.1.conv2d.0.bn.weight : False\n",
      "conv4.1.conv2d.0.bn.bias : False\n",
      "conv4.1.conv2d.1.conv1.weight : False\n",
      "conv4.1.conv2d.1.conv2.weight : False\n",
      "conv4.1.conv2d.1.bn.weight : False\n",
      "conv4.1.conv2d.1.bn.bias : False\n",
      "conv4.1.conv2d.2.conv1.weight : False\n",
      "conv4.1.conv2d.2.conv2.weight : False\n",
      "conv4.1.conv2d.2.bn.weight : False\n",
      "conv4.1.conv2d.2.bn.bias : False\n",
      "conv4.1.conv2d.3.conv1.weight : False\n",
      "conv4.1.conv2d.3.conv2.weight : False\n",
      "conv4.1.conv2d.3.bn.weight : False\n",
      "conv4.1.conv2d.3.bn.bias : False\n",
      "conv4.1.gate.fc1.weight : False\n",
      "conv4.1.gate.fc1.bias : False\n",
      "conv4.1.gate.fc2.weight : False\n",
      "conv4.1.gate.fc2.bias : False\n",
      "conv4.1.conv3.conv.weight : False\n",
      "conv4.1.conv3.bn.weight : False\n",
      "conv4.1.conv3.bn.bias : False\n",
      "conv5.conv.weight : False\n",
      "conv5.bn.weight : False\n",
      "conv5.bn.bias : False\n",
      "fc.0.weight : False\n",
      "fc.0.bias : False\n",
      "fc.1.weight : False\n",
      "fc.1.bias : False\n",
      "classifier.weight : True\n",
      "classifier.bias : True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters(): \n",
    "    print(name, ':', param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407f306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
