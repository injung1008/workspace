{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, absolute_import\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import cv2 as cv\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import argparse\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "#modeling\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    Cardinality = 32 # group 수\n",
    "    Basewidth = 64 # bottleneck 채널이 64이면 group convolution의 채널은 depth가 됩니다.\n",
    "    Depth = 4 # basewidth일 때, group convolution의 채널 수\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        C = BottleNeck.Cardinality\n",
    "        D = int(BottleNeck.Depth * out_channels / BottleNeck.Basewidth)\n",
    "\n",
    "        self.conv_residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, C * D, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(C*D),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(C*D, C*D, 3, stride=stride, padding=1, groups=BottleNeck.Cardinality, bias=False),\n",
    "            nn.BatchNorm2d(C*D),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(C*D, out_channels * BottleNeck.expansion, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion)\n",
    "        )\n",
    "\n",
    "        self.conv_shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.conv_shortcut = nn.Conv2d(in_channels, out_channels * BottleNeck.expansion, 1, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_residual(x) + self.conv_shortcut(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ResNext\n",
    "class ResNext(nn.Module):\n",
    "    def __init__(self, nblocks, num_classes=2, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.init_weights=init_weights\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=2, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2 = self._make_res_block(nblocks[0], 64, 1)\n",
    "        self.conv3 = self._make_res_block(nblocks[1], 128, 2)\n",
    "        self.conv4 = self._make_res_block(nblocks[2], 256, 2)\n",
    "        self.conv5 = self._make_res_block(nblocks[3], 512, 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(512 * BottleNeck.expansion, num_classes)\n",
    "\n",
    "        # weights initialization\n",
    "        if self.init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "    def _make_res_block(self, nblock, out_channels, stride):\n",
    "        strides = [stride] + [1] * (nblock-1)\n",
    "        res_block = nn.Sequential()\n",
    "        for i, stride in enumerate(strides):\n",
    "            res_block.add_module('dens_layer_{}'.format(i), BottleNeck(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * BottleNeck.expansion\n",
    "        return res_block\n",
    "\n",
    "    # weights initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def ResNext50():\n",
    "    return ResNext([3, 4, 6, 3])\n",
    "\n",
    "# check model\n",
    "\n",
    "\n",
    "# check model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# x = torch.randn((3, 3, 256,256)).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "#         self.path2weights = '/DATA/source/ij/pangyo/workspace/injung/worker.pt' #헬멧\n",
    "        self.path2weights = '/DATA/source/ij/pytorch_classfication/worker_wear_weights/lr0.05_loss.pt'\n",
    "        self.load()\n",
    "                \n",
    "    def load(self):      \n",
    "        path2weights = self.path2weights\n",
    "        self.model = ResNext50().to(device)\n",
    "        self.model.load_state_dict(torch.load(path2weights))\n",
    "        self.model.eval()\n",
    "        \n",
    "    def inference(self, img_list):        \n",
    "        pred_zip = [] \n",
    "        for img in img_list:\n",
    "            img = img #<class 'numpy.ndarray'>\n",
    "            img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = torch.from_numpy(img).to(DEVICE)\n",
    "            img = img.permute(2, 0, 1)\n",
    "            img = TF.resize(img,(256,256))\n",
    "            img = img.div(255)\n",
    "            img = TF.normalize(img,(0.485, 0.456, 0.406), (0.229, 0.224, 0.225))         \n",
    "            imgs = torch.stack([img])\n",
    "            output = self.model(imgs)\n",
    "            pred = output.argmax(1, keepdim=True)\n",
    "            pred = pred.cpu().numpy()\n",
    "            pred = pred.reshape(-1)\n",
    "            pred_zip.append(pred[0])\n",
    "        return pred_zip\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
