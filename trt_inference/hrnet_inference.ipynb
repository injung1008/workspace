{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b385101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA_17/trt_test/engines/hrnet_0524/hrnet_fp16_004.trt\n",
      "[05/24/2022-09:36:55] [TRT] [E] 1: [stdArchiveReader.cpp::StdArchiveReader::35] Error Code 1: Serialization (Serialization assertion safeVersionRead == safeSerializationVersion failed.Version tag does not match. Note: Current Version: 0, Serialized Engine Version: 43)\n",
      "None\n",
      "[05/24/2022-09:36:55] [TRT] [E] 4: [runtime.cpp::deserializeCudaEngine::50] Error Code 4: Internal Error (Engine deserialization failed.)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'create_execution_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22375/4231305921.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mengine\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt_engine_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m#버퍼 할당해주기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22375/4231305921.py\u001b[0m in \u001b[0;36mmake_context\u001b[0;34m(trt_engine_path, batch_size)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m#inference를 위한 context 만들기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_execution_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;31m#context 사이즈 지정 해주기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_binding_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#바인딩의 dynamic shape을 설정한다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'create_execution_context'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import common\n",
    "import tensorrt as trt\n",
    "import cv2 as cv\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import time\n",
    "\n",
    "# from utils.general import non_max_suppression\n",
    "\n",
    "ctx = cuda.Device(0).make_context()\n",
    "\n",
    "\n",
    "def img_process(img_path,batch_size):\n",
    "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img  = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    img = torch.from_numpy(img).cuda()\n",
    "    img = img.permute(2, 0, 1)\n",
    "    img = TF.resize(img,(384,288))\n",
    "    img = img.div(255)\n",
    "    img = TF.normalize(img,(0.485, 0.456, 0.406), (0.229, 0.224, 0.225))         \n",
    "    imgs = torch.stack([img])\n",
    "    return imgs\n",
    "\n",
    "# input / output buffer 생성\n",
    "def allocate_buffers(engine, batch_size, buffer_type=\"output\"): \n",
    "    res = None\n",
    "    host_mem = None\n",
    "    device_mem = None\n",
    "    \n",
    "    for binding in engine:\n",
    "        b_shape = engine.get_binding_shape(binding)\n",
    "        b_shape[0] = batch_size\n",
    "        size = trt.volume(b_shape)\n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding)) #numpy.float32\n",
    "\n",
    "        if buffer_type == 'input':\n",
    "            if engine.binding_is_input(binding):\n",
    "                host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "                device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            else:\n",
    "                continue            \n",
    "            \n",
    "        if buffer_type == 'output':\n",
    "            if engine.binding_is_input(binding):\n",
    "                continue\n",
    "            else:\n",
    "                host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "                device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            \n",
    "    res = {\n",
    "        'host_mem' : host_mem\n",
    "        ,'device_mem' : device_mem\n",
    "    }\n",
    "    \n",
    "    return res\n",
    "      \n",
    "\n",
    "def do_inference_v2(context, input_data, input, output, stream):\n",
    "    res = None\n",
    "    ctx.push()\n",
    "    bindings = None     \n",
    "    if input == None : # 입력 버퍼 할당 하지 않은경우(input_data == tensor cuda)\n",
    "        bindings = [\n",
    "            int(input_data.contiguous().data_ptr())\n",
    "            ,int(output['device_mem'])\n",
    "        ]        \n",
    "    else :\n",
    "        bindings = [\n",
    "            int(input['device_mem'])\n",
    "            ,int(output['device_mem'])\n",
    "        ]        \n",
    "        \n",
    "        input['host_mem'] = input_data        \n",
    "        cuda.memcpy_htod_async(input['device_mem'], input['host_mem'], stream)\n",
    "    \n",
    "    context.execute_async_v2(bindings,stream_handle=stream.handle)\n",
    "    cuda.memcpy_dtoh_async(output['host_mem'], output['device_mem'], stream)\n",
    "\n",
    "    stream.synchronize()\n",
    "    ctx.pop()\n",
    "\n",
    "    res = output['host_mem']\n",
    "    return res\n",
    "\n",
    "def make_context(trt_engine_path, batch_size):\n",
    "    logger = trt.Logger(trt.Logger.WARNING)\n",
    "    runtime = trt.Runtime(logger)\n",
    "    #엔진 로드 \n",
    "    print(trt_engine_path)\n",
    "    engine = load_engine(runtime, trt_engine_path)\n",
    "    print(engine)\n",
    "    #inference를 위한 context 만들기\n",
    "    context = engine.create_execution_context()\n",
    "    #context 사이즈 지정 해주기\n",
    "    context.set_binding_shape(0, (batch_size, 3, 384, 256)) #바인딩의 dynamic shape을 설정한다 \n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    return engine ,context, stream\n",
    "\n",
    "\n",
    "\n",
    "def load_engine(trt_runtime, engine_path):\n",
    "    trt.init_libnvinfer_plugins(None, \"\")             \n",
    "    with open(engine_path, 'rb') as f:\n",
    "        engine_data = f.read()\n",
    "    engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "    return engine\n",
    "\n",
    "def make_output(result,batch_size):\n",
    "    result = np.reshape(result,(batch_size,17,-1,-1))    \n",
    "    outputs = torch.Tensor(result)\n",
    "    outputs = outputs.view([batch_size, 17,-1,]) \n",
    "    num_classes = 80\n",
    "    confthre =0.5\n",
    "    nmsthre  =0.3\n",
    "    outputs = postprocess(\n",
    "        outputs, num_classes, confthre,\n",
    "        nmsthre, class_agnostic=True)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "\n",
    "#엔진 경로 설정해주기 \n",
    "trt_engine_path = '/DATA_17/trt_test/engines/hrnet_0524/hrnet_fp16_004.trt'\n",
    "\n",
    "#배치사이즈 설정하기\n",
    "batch_size = 1\n",
    "#이미지 경로 설정     \n",
    "# img_path = '/DATA_17/ij/worker.jpg'   \n",
    "img_path = '/DATA_17/hjjo/selftest/deep-high-resolution-net.pytorch/person_23_0_1.jpg'  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "engine ,context, stream = make_context(trt_engine_path, batch_size)\n",
    "\n",
    "#버퍼 할당해주기 \n",
    "inputs = allocate_buffers(engine, batch_size, buffer_type=\"input\")\n",
    "output = allocate_buffers(engine, batch_size, buffer_type=\"output\")\n",
    "\n",
    "img_stack = img_process(img_path,batch_size)\n",
    "\n",
    "\n",
    "# input_data = torch.tensor(img_stack).cuda() #input 버퍼할당해 주지 않고 데이터를 바로 보낼때 \n",
    "result = do_inference_v2(context, img_stack, None, output, stream) #결과 생성\n",
    "result = torch.from_numpy(result).cuda()\n",
    "print('result', result)\n",
    "pred = result.argmax(0)\n",
    "print(pred)\n",
    "# pred = pred.cpu().numpy()\n",
    "# pred = pred.reshape(-1)\n",
    "\n",
    "# print(pred)\n",
    "# pred = pred.cpu().numpy()\n",
    "# pred = pred.reshape(-1)\n",
    "# pred_zip.append(pred[0])\n",
    "\n",
    "\n",
    "# output = make_output(result,batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98fae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 a\n",
      "1 2 b\n",
      "2 3 c\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "ac = ['a','b','c']\n",
    "for idx, (i,x) in enumerate(zip(a,ac)):\n",
    "    print(idx,i,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765086a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
