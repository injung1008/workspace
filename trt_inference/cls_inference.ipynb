{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecae1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TensorRT] WARNING: The logger passed into createInferRuntime differs from one already provided for an existing builder, runtime, or refitter. TensorRT maintains only a single logger pointer at any given time, so the existing value, which can be retrieved with getLogger(), will be used instead. In order to use a new logger, first destroy all existing builder, runner or refitter objects.\n",
      "\n",
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n",
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgs.shape torch.Size([4, 3, 256, 128])\n",
      "result torch.Size([4, 3])\n",
      "tensor([[  8.0469,  -5.5156, -26.7969],\n",
      "        [  8.0469,  -5.5156, -26.7969],\n",
      "        [  8.0469,  -5.5156, -26.7969],\n",
      "        [  8.0469,  -5.5156, -26.7969]], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor(0, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# import argparse\n",
    "# import os\n",
    "# import sys\n",
    "# import numpy as np\n",
    "# import pycuda.autoinit\n",
    "# import pycuda.driver as cuda\n",
    "# import common\n",
    "# import tensorrt as trt\n",
    "# import cv2 as cv\n",
    "# import torchvision\n",
    "# import torch\n",
    "# import torchvision.transforms.functional as TF\n",
    "# import time\n",
    "# import load_engine\n",
    "# # from utils.general import non_max_suppression\n",
    "\n",
    "\n",
    "# def img_process(img_path,batch_size,input_w,input_h):\n",
    "#     img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "#     img  = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "#     img = torch.from_numpy(img).cuda()\n",
    "#     img = img.permute(2, 0, 1)\n",
    "#     img = TF.resize(img,(input_h,input_w))\n",
    "#     img = img.div(255)\n",
    "#     img = TF.normalize(img,(0.485, 0.456, 0.406), (0.229, 0.224, 0.225))         \n",
    "#     img_list = [img for _ in range(batch_size)]\n",
    "#     imgs = torch.stack(img_list,dim=0)\n",
    "#     print('imgs.shape',imgs.shape)\n",
    "#     return imgs\n",
    "\n",
    "\n",
    "# #엔진 경로 설정해주기 \n",
    "# trt_engine_path = '/DATA_17/ij/trt_inference/make_trt/worker.trt'\n",
    "\n",
    "# #배치사이즈 설정하기\n",
    "# batch_size = 4\n",
    "# #이미지 경로 설정     \n",
    "# img_path = '/DATA_17/ij/worker.jpg'   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# input_w = 128\n",
    "# input_h = 256\n",
    "\n",
    "# #Engine class 소환 \n",
    "# Engine = load_engine.Engine()    \n",
    "# engine,context, stream, ctx = Engine.make_context(trt_engine_path)\n",
    "# #버퍼 할당해주기 \n",
    "# Engine.allocate_buffers_all(batch_size,engine)\n",
    "\n",
    "\n",
    "# img_stack = img_process(img_path,batch_size,input_w,input_h)\n",
    "\n",
    "\n",
    "\n",
    "# # input_data = torch.tensor(img_stack).cuda() #input 버퍼할당해 주지 않고 데이터를 바로 보낼때 \n",
    "# result = Engine.do_inference_v2(context, img_stack, None, stream,input_w,input_h) #결과 생성\n",
    "\n",
    "# result = torch.from_numpy(result).cuda()\n",
    "# result = result.reshape(batch_size,-1) \n",
    "# print('result', result.shape)\n",
    "# print(result)\n",
    "# pred = result[0].argmax(0)\n",
    "# pred1 = result[1].argmax(0)\n",
    "# print(pred,pred1)\n",
    "\n",
    "\n",
    "# ctx.pop()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "405d6f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 300, 200])\n",
      "torch.Size([2, 3, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import common\n",
    "import tensorrt as trt\n",
    "import cv2 as cv\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import time\n",
    "\n",
    "a = np.random.randn(300,200,3)\n",
    "# img = cv.imread('/DATA_17/ij/worker.jpg', cv.IMREAD_COLOR)\n",
    "print(img.shape) #(h,w,3)\n",
    "img = torch.from_numpy(a).cuda()\n",
    "img = img.permute(2, 0, 1)\n",
    "img = TF.resize(img,(256,128))\n",
    "img = img.div(255)\n",
    "img = TF.normalize(img,(0.485, 0.456, 0.406), (0.229, 0.224, 0.225))         \n",
    "img_list = [img for _ in range(2)]\n",
    "imgs = torch.stack(img_list,dim=0)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25819ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
