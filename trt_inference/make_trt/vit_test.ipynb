{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe013b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[1]], device='cuda:0')], [tensor([[1]], device='cuda:0')]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.backends import cudnn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# import transforms\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import time \n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "import cv2 as cv\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):        \n",
    "        self.model_path = '/DATA_17/ij/trt_inference/make_trt/helme_vit_2.pth'\n",
    "        self.load()\n",
    "                \n",
    "    def load(self):       \n",
    "        self.model = torch.load(self.model_path).to(DEVICE)\n",
    "        self.model.eval()\n",
    "######\n",
    "\n",
    "        \n",
    "    def inference(self, img_list):        \n",
    "        pred_zip = [] \n",
    "        end_zip = [] \n",
    "        #시간측정\n",
    "        \n",
    "        for img in img_list:\n",
    "            start = time.time()\n",
    "            img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = torch.from_numpy(img).to(DEVICE)\n",
    "            img = img.permute(2, 0, 1)\n",
    "            img = TF.resize(img,(224,224))\n",
    "            img = img.div(255)\n",
    "            img = TF.normalize(img,(0.5, 0.5, 0.5), (0.5, 0.5, 0.5))         \n",
    "            imgs = torch.stack([img])\n",
    "            output = self.model(imgs)\n",
    "            pred = output.argmax(1,keepdim=True)\n",
    "            pred_zip.append([pred])\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "        return pred_zip\n",
    "\n",
    "img_path = '/DATA_17/ij/worker.jpg'   \n",
    "img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "img_list = [img for _ in range(2)]\n",
    "c= Classifier()\n",
    "pred_zip = c.inference(img_list)\n",
    "print(pred_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589aa88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
