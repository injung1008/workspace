{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a9129e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n",
      "[TensorRT] WARNING: TensorRT was linked against cuDNN 8.2.1 but loaded cuDNN 8.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.0067217350006103516\n",
      "time 0.007361888885498047\n",
      "time 0.006139993667602539\n",
      "time 0.0060307979583740234\n",
      "time 0.0060253143310546875\n",
      "time 0.006036281585693359\n",
      "time 0.0060083866119384766\n",
      "time 0.006021022796630859\n",
      "time 0.006024360656738281\n",
      "time 0.0060214996337890625\n",
      "time 0.006014108657836914\n",
      "time 0.0060138702392578125\n",
      "time 0.006000995635986328\n",
      "time 0.005984067916870117\n",
      "time 0.005983591079711914\n",
      "time 0.005985736846923828\n",
      "time 0.006027936935424805\n",
      "time 0.005954742431640625\n",
      "time 0.005965709686279297\n",
      "time 0.0059604644775390625\n",
      "time 0.005945682525634766\n",
      "time 0.0059359073638916016\n",
      "time 0.005930185317993164\n",
      "time 0.005944728851318359\n",
      "time 0.0059299468994140625\n",
      "time 0.005915164947509766\n",
      "time 0.005934715270996094\n",
      "time 0.005910158157348633\n",
      "time 0.0059587955474853516\n",
      "time 0.00590825080871582\n",
      "time 0.005922794342041016\n",
      "time 0.00593113899230957\n",
      "time 0.005914449691772461\n",
      "time 0.005904197692871094\n",
      "time 0.005982875823974609\n",
      "time 0.006094455718994141\n",
      "time 0.0059397220611572266\n",
      "time 0.0059278011322021484\n",
      "time 0.0059185028076171875\n",
      "time 0.005919933319091797\n",
      "time 0.005917787551879883\n",
      "time 0.005913257598876953\n",
      "time 0.00590825080871582\n",
      "time 0.005880117416381836\n",
      "time 0.0058939456939697266\n",
      "time 0.0059239864349365234\n",
      "time 0.005877256393432617\n",
      "time 0.00587010383605957\n",
      "time 0.005870342254638672\n",
      "time 0.0058896541595458984\n",
      "time 0.005868196487426758\n",
      "time 0.00587010383605957\n",
      "time 0.005878448486328125\n",
      "time 0.005867481231689453\n",
      "time 0.005855083465576172\n",
      "time 0.0058460235595703125\n",
      "time 0.005860567092895508\n",
      "time 0.005875110626220703\n",
      "time 0.005872011184692383\n",
      "time 0.005875587463378906\n",
      "time 0.005877256393432617\n",
      "time 0.005883216857910156\n",
      "time 0.00592494010925293\n",
      "time 0.0058956146240234375\n",
      "time 0.005876064300537109\n",
      "time 0.005882740020751953\n",
      "time 0.005861520767211914\n",
      "time 0.005934715270996094\n",
      "time 0.00586390495300293\n",
      "time 0.005936384201049805\n",
      "time 0.005894184112548828\n",
      "time 0.005850315093994141\n",
      "time 0.0058710575103759766\n",
      "time 0.005867719650268555\n",
      "time 0.0058841705322265625\n",
      "time 0.005916595458984375\n",
      "time 0.005933284759521484\n",
      "time 0.005865335464477539\n",
      "time 0.005864381790161133\n",
      "time 0.00586700439453125\n",
      "time 0.005876779556274414\n",
      "time 0.005853176116943359\n",
      "time 0.005878448486328125\n",
      "time 0.0058574676513671875\n",
      "time 0.005867719650268555\n",
      "time 0.005858421325683594\n",
      "time 0.005870342254638672\n",
      "time 0.005872964859008789\n",
      "time 0.005889177322387695\n",
      "time 0.005887269973754883\n",
      "time 0.005872011184692383\n",
      "time 0.005875825881958008\n",
      "time 0.005876779556274414\n",
      "time 0.005927085876464844\n",
      "time 0.005868434906005859\n",
      "time 0.006003618240356445\n",
      "time 0.0058820247650146484\n",
      "time 0.005927562713623047\n",
      "평균 시간 :  0.005942456576288963\n",
      "[tensor([[390.1489,  48.4131, 547.3511, 422.5869,   0.9868,   0.9546,   0.0000],\n",
      "        [ 51.7764,  47.1723, 259.2236, 422.0776,   0.9888,   0.9482,   0.0000],\n",
      "        [221.2948,  35.4743, 406.7052, 421.5256,   0.9897,   0.9360,   0.0000],\n",
      "        [293.8252, 137.6245, 319.6748, 198.3755,   0.9800,   0.8735,  27.0000],\n",
      "        [467.4314, 137.4640, 494.5686, 223.2860,   0.9414,   0.8882,  27.0000]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt\n",
    "import cv2 as cv\n",
    "import torchvision\n",
    "import torch\n",
    "import time\n",
    "import common\n",
    "import vis\n",
    "import coco_classes\n",
    "\n",
    "\n",
    "def postprocess(prediction, num_classes, conf_thre=0.7, nms_thre=0.45, class_agnostic=False):\n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
    "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
    "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
    "\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    for i, image_pred in enumerate(prediction):\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "        class_conf, class_pred = torch.max(image_pred[:, 5: 5 + num_classes], 1, keepdim=True)\n",
    "\n",
    "        conf_mask = (image_pred[:, 4] * class_conf.squeeze() >= conf_thre).squeeze()\n",
    "        detections = torch.cat((image_pred[:, :5], class_conf, class_pred.float()), 1)\n",
    "        detections = detections[conf_mask]\n",
    "        if not detections.size(0):\n",
    "            continue\n",
    "\n",
    "        if class_agnostic:\n",
    "            nms_out_index = torchvision.ops.nms(\n",
    "                detections[:, :4],\n",
    "                detections[:, 4] * detections[:, 5],\n",
    "                nms_thre,\n",
    "            )\n",
    "        else:\n",
    "            nms_out_index = torchvision.ops.batched_nms(\n",
    "                detections[:, :4],\n",
    "                detections[:, 4] * detections[:, 5],\n",
    "                detections[:, 6],\n",
    "                nms_thre,\n",
    "            )\n",
    "\n",
    "        detections = detections[nms_out_index]\n",
    "        if output[i] is None:\n",
    "            output[i] = detections\n",
    "        else:\n",
    "            output[i] = torch.cat((output[i], detections))\n",
    "\n",
    "    return output\n",
    "\n",
    "def preproc(img, input_size, swap=(2, 0, 1)):\n",
    "    if len(img.shape) == 3:\n",
    "        padded_img = np.ones((input_size[0], input_size[1], 3), dtype=np.uint8) * 114\n",
    "    else:\n",
    "        padded_img = np.ones(input_size, dtype=np.uint8) * 114\n",
    "\n",
    "    r = min(input_size[0] / img.shape[0], input_size[1] / img.shape[1])\n",
    "    resized_img = cv.resize(\n",
    "        img,\n",
    "        (int(img.shape[1] * r), int(img.shape[0] * r)),\n",
    "        interpolation=cv.INTER_LINEAR,\n",
    "    ).astype(np.uint8)\n",
    "    padded_img[: int(img.shape[0] * r), : int(img.shape[1] * r)] = resized_img\n",
    "\n",
    "    padded_img = padded_img.transpose(swap)\n",
    "    padded_img = np.ascontiguousarray(padded_img, dtype=np.float32)\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "\n",
    "def img_process(img_path,batch_size):\n",
    "    ori_img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "    img = preproc(ori_img,(640,640), swap=(2, 0, 1))\n",
    "    img_list = [img for _ in range(batch_size)]\n",
    "    img_stack = np.stack(img_list, axis=0)\n",
    "    return img_stack, ori_img\n",
    "\n",
    "\n",
    "\n",
    "def make_output(result,batch_size):\n",
    "    num_classes = 80\n",
    "    confthre =0.5\n",
    "    nmsthre  =0.3\n",
    "    result = np.reshape(result,(batch_size,1,-1))    \n",
    "    outputs = torch.Tensor(result)\n",
    "    outputs = outputs.view([batch_size, -1,num_classes+5]) \n",
    "    outputs = postprocess(\n",
    "        outputs, num_classes, confthre,\n",
    "        nmsthre, class_agnostic=True)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def visual(img, output, ratio, cls_conf=0.35):\n",
    "\n",
    "    if output is None:\n",
    "        return img\n",
    "    output = output.cpu()\n",
    "\n",
    "    bboxes = output[:, 0:4]\n",
    "\n",
    "    # preprocessing: resize\n",
    "    bboxes /= ratio\n",
    "\n",
    "    cls = output[:, 6]\n",
    "    scores = output[:, 4] * output[:, 5]\n",
    "\n",
    "    vis_res = vis.vis(img, bboxes, scores, cls, cls_conf, coco_classes.COCO_CLASSES)\n",
    "\n",
    "    return vis_res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#엔진 경로 설정해주기 \n",
    "trt_engine_path = '/DATA_17/ij/trt_inference/yolox_m.trt'\n",
    "\n",
    "#배치사이즈 설정하기\n",
    "batch_size = 1\n",
    "#이미지 경로 설정     \n",
    "img_path = '/DATA_17/ij/test_image.jpeg'   \n",
    "\n",
    "save_img_path = '/DATA_17/ij/test.jpeg'   \n",
    "\n",
    "#Engine class 소환 \n",
    "Engine = common.Engine()      \n",
    "#inference에 필요한 context 만들어주기  \n",
    "engine ,context, stream = Engine.make_context(trt_engine_path, batch_size)\n",
    "\n",
    "#버퍼 할당해주기 \n",
    "inputs = Engine.allocate_buffers(engine, batch_size, 'input')\n",
    "output = Engine.allocate_buffers(engine, batch_size, 'output')\n",
    "\n",
    "img_stack, ori_img = img_process(img_path,batch_size)\n",
    "\n",
    "\n",
    "average = 0\n",
    "loop_cnt = 100\n",
    "for i in range(loop_cnt):\n",
    "    s3= time.time()\n",
    "    input_data = torch.tensor(img_stack).cuda() #input 버퍼할당해 주지 않고 데이터를 바로 보낼때 \n",
    "    result = Engine.do_inference_v2(context, input_data, None, output, stream) #결과 생성\n",
    "    e3 = time.time()\n",
    "    if i < 2:\n",
    "        continue\n",
    "    print('time',e3 - s3)\n",
    "    average += e3 - s3\n",
    "print('평균 시간 : ',average/(loop_cnt-2))\n",
    "\n",
    "\n",
    "#postprocess\n",
    "outputs = make_output(result,batch_size)\n",
    "print(outputs)\n",
    "\n",
    "ratio = min(640 / ori_img.shape[0], 640 / ori_img.shape[1])\n",
    "result_image = visual(ori_img, outputs[0], ratio, cls_conf=0.35)\n",
    "cv.imwrite(save_img_path, result_image)\n",
    "\n",
    "\n",
    "# outputs 예시 (박스,score,score,class)\n",
    "# [tensor([[390.1489,  48.4131, 547.3511, 422.5869,   0.9863,   0.9541,   0.0000],\n",
    "#         [ 51.7764,  47.5381, 259.2236, 421.7119,   0.9883,   0.9478,   0.0000],\n",
    "#         [221.2948,  35.4743, 406.7052, 421.5256,   0.9897,   0.9360,   0.0000],\n",
    "#         [293.8126, 137.6245, 319.6874, 198.3755,   0.9800,   0.8730,  27.0000],\n",
    "#         [467.4181, 137.4220, 494.5819, 223.3280,   0.9419,   0.8882,  27.0000]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104c621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
